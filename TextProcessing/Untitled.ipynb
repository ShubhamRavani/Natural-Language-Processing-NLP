{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2454636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcae03e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this movie, it's funny.\n",
      "I hate this movie.\n",
      "This was awesome! I like it.\n",
      "Nice one. I love it.\n"
     ]
    }
   ],
   "source": [
    "#Reading file programmatically\n",
    "f = open(\"story.txt\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68afbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n"
     ]
    }
   ],
   "source": [
    "#split the text line-by-line (separated by full-stop)\n",
    "\n",
    "with open(\"story.txt\", \"r\") as file:\n",
    "    documents = file.read().splitlines()\n",
    "    \n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40f65ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'this', 'movie', ',', 'it', \"'s\", 'funny', '.', 'I', 'hate', 'this', 'movie', '.', 'This', 'was', 'awesome', '!', 'I', 'like', 'it', '.', 'Nice', 'one', '.', 'I', 'love', 'it', '.']\n"
     ]
    }
   ],
   "source": [
    "#split the entire text word-by-word (separated by white space)\n",
    "#Word Tokenization\n",
    "f = open(\"story.txt\", \"r\")\n",
    "text = f.read()\n",
    "output = nltk.word_tokenize(text)\n",
    "f.close()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "474c2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the list-of-words (to find out most used keywords)\n",
    "\n",
    "file = open(\"story.txt\", \"r\")\n",
    "a= file.read()\n",
    "wordcount = {}\n",
    "# To eliminate duplicates, remember to split by punctuation, and use case demiliters.\n",
    "for word in a.lower().split():\n",
    "    \n",
    "    word = word.replace(\".\",\"\")\n",
    "\n",
    "#     if word not in stopwords:\n",
    "    if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "    else:\n",
    "            wordcount[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27e81fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many most common words to print: 4\n",
      "\n",
      " OK. The 4 most common words are as follows\n",
      "\n",
      "i :  4\n",
      "this :  3\n",
      "like :  2\n",
      "it :  2\n"
     ]
    }
   ],
   "source": [
    "# Print most common word\n",
    "n_print = int(input(\"How many most common words to print: \"))\n",
    "print(\"\\n OK. The {} most common words are as follows\\n\".format(n_print))\n",
    "word_counter = collections.Counter(wordcount)\n",
    "for word, count in word_counter.most_common(n_print):\n",
    "    print(word, \": \", count)\n",
    "# Close the file\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "977d7910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'like', 'movie', ',', \"'s\", 'funny', '.', 'I', 'hate', 'movie', '.', 'This', 'awesome', '!', 'I', 'like', '.', 'Nice', 'one', '.', 'I', 'love', '.']\n"
     ]
    }
   ],
   "source": [
    "#separate the list-of-joining-words (to ignore them)\n",
    "\n",
    "f = open(\"story.txt\")\n",
    "text = f.read()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "# print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8986f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.522\n",
       "1    0.100\n",
       "2    0.378\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiments of the text â€“positive (pros), negative (cons)or neutral\n",
    "#Creating a textblob object and assigning the sentiment property\n",
    "f = open(\"story.txt\", \"r\")\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def print_sentiment_scores(tweets):\n",
    "    vadersenti = analyser.polarity_scores(tweets)\n",
    "    return pd.Series([vadersenti['pos'], vadersenti['neg'], vadersenti['neu']])\n",
    "\n",
    "text = f.read()\n",
    "\n",
    "print_sentiment_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569b806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
